{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bd0214f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in ./anaconda3/lib/python3.10/site-packages (3.3.2)\n",
      "Requirement already satisfied: py4j==0.10.9.5 in ./anaconda3/lib/python3.10/site-packages (from pyspark) (0.10.9.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5ee2cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import size,stddev \n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import mean, col\n",
    "import pyspark.sql.functions as func\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# spark = SparkSession.builder.master(\"local\")\\\n",
    "#         .config(\"spark.port.maxRetries\", 100)\\\n",
    "#         .config(\"spark.executor.instances\", \"6\")\\\n",
    "#         .config(\"spark.executor.cores\", \"4\")\\\n",
    "#         .config(\"spark.executor.memory\", \"8G\")\\\n",
    "#         .config(\"spark.driver.memory\", \"2G\")\\\n",
    "#         .config(\"spark.dynamicAllocation.enabled\", \"false\")\\\n",
    "#         .config(\"spark.yarn.queue\", \"Low\")\\\n",
    "#         .config(\"spark.port.maxRetries\", 100)\\\n",
    "#         .appName(\"New_Data_Reader_V0\")\\\n",
    "#         .getOrCreate()\n",
    "\n",
    "spark = SparkSession.builder.master(\"local\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f3b3f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "\n",
    "years=['2010','2011','2012','2013','2014','2015','2016','2017','2018','2019','2020','2021','2022']\n",
    "#Lopp over the years and process the data\n",
    "for year in years:\n",
    "    # Read the CSV files for the current year\n",
    "    path=\"/Users/hasinirasagna/Downloads/data/\"+year\n",
    "    df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"delimiter\",\",\").csv(path+\"/*.csv\")\n",
    "    df.createOrReplaceTempView(\"temp_view\")\n",
    "    # Find the hottest day for the year\n",
    "    temperature1 = spark.sql(\"SELECT STATION,NAME,MAX, DATE FROM temp_view WHERE MAX = (SELECT MAX(MAX) FROM temp_view );\")\n",
    "    print(\"Hottest day for \"+ year)\n",
    "    temperature1.show()\n",
    "    \n",
    "    \n",
    "# Find the coldest day of January across all years\n",
    "path=\"/Users/hasinirasagna/Downloads/data/\"\n",
    "df1 = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"delimiter\",\",\").csv(path + \"/*/*.csv\")  \n",
    "df1.createOrReplaceTempView(\"COLD\")\n",
    "coldest=spark.sql(\"SELECT STATION,NAME,DATE,MIN FROM cold WHERE MIN = (SELECT MIN(MIN) FROM cold WHERE DATE LIKE '%-01-%') AND DATE LIKE '%-01-%' ORDER BY DATE\")\n",
    "print(\"Cold Day of January\")\n",
    "coldest.show()\n",
    "\n",
    "# Find the maximum and minimum precipitation for year 2015\n",
    "temperature2 = spark.sql(\"SELECT STATION,NAME,PRCP, DATE FROM COLD WHERE PRCP = (SELECT MAX(PRCP) FROM COLD where PRCP!=99.99  AND YEAR(DATE) = 2015) and YEAR(DATE) = 2015 limit 1\")\n",
    "temperature3 = spark.sql(\"SELECT STATION,NAME,PRCP, DATE FROM COLD WHERE PRCP = (SELECT MIN(PRCP) FROM COLD where PRCP!=0.0) and YEAR(DATE) = 2015 limit 1\")\n",
    "print(\" 3. Max Precipitation for year 2015\")\n",
    "temperature2.show()\n",
    "print(\"3. Min Precipitation for year 2015\")\n",
    "temperature3.show()\n",
    "\n",
    "# Calculate the percentage of no gust values for year 2019\n",
    "df1 = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"delimiter\",\",\").csv(path + \"/*/*.csv\")  \n",
    "df1.createOrReplaceTempView(\"GUSTY\")\n",
    "No_gust=spark.sql(\"Select count(GUST) from GUSTY WHERE YEAR(DATE) = 2019 AND GUST==999.9\").collect()[0]\n",
    "No_gust=No_gust[\"count(GUST)\"]\n",
    "TotalCount=spark.sql(\"Select count(GUST) from GUSTY WHERE YEAR(DATE) = 2019\").collect()[0]\n",
    "TotalCount=TotalCount[\"count(GUST)\"]\n",
    "print('Percentage of Null Gust values is ',str((No_gust/TotalCount)*100))\n",
    "\n",
    "# Calculate the mean, median, mode, and standard deviation of temperature for year 2020\n",
    "df1.createOrReplaceTempView(\"NEW\")\n",
    "temperature6 = spark.sql(\"SELECT TEMP,MONTH(DATE) FROM NEW where YEAR(DATE) = 2020\")\n",
    "print(\"Mean of TEMP in 2020\")\n",
    "temperature6.groupBy(\"MONTH(DATE)\").agg(mean(\"TEMP\")).orderBy(\"MONTH(DATE)\").show(truncate=False)\n",
    "print(\"Median of TEMP in 2020\")\n",
    "temperature6.groupBy(\"MONTH(DATE)\").agg(func.percentile_approx(\"TEMP\", 0.5).alias(\"median\")).orderBy(\"MONTH(DATE)\").show()\n",
    "print(\"Mode of TEMP in 2020\")\n",
    "mode=spark.sql(\"with tv1 as (Select month(date) as MONTH, temp,count(temp) over (partition by temp, month(date)) as cnt from NEW where YEAR(DATE) = 2020),  tv2 as (select distinct MONTH, max(cnt) over(partition by MONTH) mx from tv1) select distinct tv2.MONTH , max(tv1.temp) over (partition by tv2.MONTH) as Mode from tv1, tv2 where  tv1.MONTH=tv2.MONTH and tv1.cnt=tv2.mx order by tv2.MONTH\") \n",
    "mode.show()\n",
    "print(\"Standard Deviation of TEMP in 2020\")\n",
    "temperature6.groupBy(\"MONTH(DATE)\").agg(stddev(\"TEMP\")).orderBy(\"MONTH(DATE)\").show(truncate=False)\n",
    "with open('/Users/hasinirasagna/Downloads/Result.txt', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec3419e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
